{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcion del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diccionario de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diccionario de datos del dataset principal: db_retail\n",
    "\n",
    "| Nombre | Nombre de columna | Definicion | Tipo de dato |\n",
    "|--------|-------------------|------------|--------------|\n",
    "|ID |ID |Identificador unico de la fila |Int\n",
    "|Nombre del producto |ProductName |Nombre del producto vendido |String\n",
    "|Cantidad |ProductQuantity |Cantidad de unidades vendidas |Int\n",
    "|Precio por unidad |Unit Price | Precio de la unidad vendida |Float\n",
    "|Pais |Country |Pais en el que se vendio el producto |String\n",
    "|Categoria |Category |Categoria del producto ordenado |String\n",
    "|Fecha de orden |OrderDate |Fecha en la que se hizo la orden |DateTime\n",
    "|Fecha de llegada |ArrivalDate |Fecha en la orden llego al cliente |DateTime\n",
    "|Venta |Sales |Valor total de la venta |Float \n",
    "|Ciudad |City |Ciudad donde se hizo la orden |String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elaboracion del taller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias y dependencias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType, FloatType, IntegerType, DateType #tipos de datos para elaboracion del schema\n",
    "from pyspark.sql.functions import * #  countDistinct, col, desc, asc, isnan, when, count, avg, min, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"session\").getOrCreate() #creando la sesion de spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar el dataset y convertirlo a JSON, Parquet y CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./datasets/input/db_retail.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName</th>\n",
       "      <th>ProductQuantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Country</th>\n",
       "      <th>Category</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>ArrivalDate</th>\n",
       "      <th>Sales</th>\n",
       "      <th>City</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170878</th>\n",
       "      <td>Sauder Forest Hills Library, Woodland Oak Finish</td>\n",
       "      <td>1</td>\n",
       "      <td>359.499</td>\n",
       "      <td>USA</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>2020-12-26 06:40:15</td>\n",
       "      <td>2021-05-16 07:19:38</td>\n",
       "      <td>359.499</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>170878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42185</th>\n",
       "      <td>RETROSPOT TEA SET CERAMIC 11 PC</td>\n",
       "      <td>6</td>\n",
       "      <td>4.950</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Furnishing</td>\n",
       "      <td>2016-10-06 07:56:26</td>\n",
       "      <td>2017-01-11 01:45:55</td>\n",
       "      <td>29.700</td>\n",
       "      <td>Kobenhavn</td>\n",
       "      <td>42185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111120</th>\n",
       "      <td>VINTAGE CHRISTMAS GIFT SACK</td>\n",
       "      <td>4</td>\n",
       "      <td>4.150</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Art</td>\n",
       "      <td>2016-02-25 10:37:13</td>\n",
       "      <td>2021-09-24 23:05:49</td>\n",
       "      <td>16.600</td>\n",
       "      <td>Gensve</td>\n",
       "      <td>111120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ProductName  ProductQuantity  \\\n",
       "170878  Sauder Forest Hills Library, Woodland Oak Finish                1   \n",
       "42185                   RETROSPOT TEA SET CERAMIC 11 PC                 6   \n",
       "111120                       VINTAGE CHRISTMAS GIFT SACK                4   \n",
       "\n",
       "        UnitPrice      Country    Category           OrderDate  \\\n",
       "170878    359.499          USA   Furniture 2020-12-26 06:40:15   \n",
       "42185       4.950      Denmark  Furnishing 2016-10-06 07:56:26   \n",
       "111120      4.150  Switzerland         Art 2016-02-25 10:37:13   \n",
       "\n",
       "               ArrivalDate    Sales           City      ID  \n",
       "170878 2021-05-16 07:19:38  359.499  San Francisco  170878  \n",
       "42185  2017-01-11 01:45:55   29.700      Kobenhavn   42185  \n",
       "111120 2021-09-24 23:05:49   16.600         Gensve  111120  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./datasets/output/db_retail.csv\") #exportar a csv\n",
    "df.to_parquet(\"./datasets/output/db_retail.parquet\", engine = 'pyarrow') #exportar a parquet\n",
    "df.to_json(\"./datasets/output/db_retail.json\", orient=\"records\") #exportar a json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar JSON, Parquet y CSV a PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leyendo con spark.read.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "|_c0|         ProductName|ProductQuantity|UnitPrice|Country|  Category|          OrderDate|        ArrivalDate|Sales|  City| ID|\n",
      "+---+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "|  0|WHITE HANGING HEA...|              6|     2.55|  Italy|Furnishing|2020-03-01 22:00:44|2021-11-18 00:37:57| 15.3|Torino|  0|\n",
      "|  1|CREAM CUPID HEART...|              8|     2.75| Sweden|Furnishing|2018-04-20 19:27:37|2021-10-30 13:07:25| 22.0| Boras|  1|\n",
      "+---+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lectura del CSV\n",
    "df_spark = spark.read.format(\"csv\")\\\n",
    "                            .option(\"header\", \"true\")\\\n",
    "                            .option(\"nullValue\", \"?\")\\\n",
    "                            .option(\"encoding\", \"utf8\")\\\n",
    "                            .load(\"./datasets/output/db_retail.csv\")\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "|         ProductName|ProductQuantity|UnitPrice|Country|  Category|          OrderDate|        ArrivalDate|Sales|  City| ID|\n",
      "+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "|WHITE HANGING HEA...|              6|     2.55|  Italy|Furnishing|2020-03-01 17:00:44|2021-11-17 19:37:57| 15.3|Torino|  0|\n",
      "|CREAM CUPID HEART...|              8|     2.75| Sweden|Furnishing|2018-04-20 14:27:37|2021-10-30 08:07:25| 22.0| Boras|  1|\n",
      "+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lectura del parquet\n",
    "df_spark = spark.read.format(\"parquet\")\\\n",
    "                        .option(\"header\", \"true\")\\\n",
    "                        .option(\"nullValue\", \"?\")\\\n",
    "                        .option(\"encoding\", \"utf8\")\\\n",
    "                        .load(\"./datasets/output/db_retail.parquet\")\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-------+---+-------------+--------------------+---------------+-----+---------+\n",
      "|  ArrivalDate|  Category|  City|Country| ID|    OrderDate|         ProductName|ProductQuantity|Sales|UnitPrice|\n",
      "+-------------+----------+------+-------+---+-------------+--------------------+---------------+-----+---------+\n",
      "|1637195877000|Furnishing|Torino|  Italy|  0|1583100044000|WHITE HANGING HEA...|              6| 15.3|     2.55|\n",
      "|1635599245000|Furnishing| Boras| Sweden|  1|1524252457000|CREAM CUPID HEART...|              8| 22.0|     2.75|\n",
      "+-------------+----------+------+-------+---+-------------+--------------------+---------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lectura del JSON\n",
    "df_spark = spark.read.format(\"json\")\\\n",
    "                        .option(\"encoding\",\"utf8\")\\\n",
    "                        .load(\"./datasets/output/db_retail.json\")\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leyendo con sprk.read.dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "|_c0|         ProductName|ProductQuantity|UnitPrice|Country|  Category|          OrderDate|        ArrivalDate|Sales|  City| ID|\n",
      "+---+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "|  0|WHITE HANGING HEA...|              6|     2.55|  Italy|Furnishing|2020-03-01 22:00:44|2021-11-18 00:37:57| 15.3|Torino|  0|\n",
      "|  1|CREAM CUPID HEART...|              8|     2.75| Sweden|Furnishing|2018-04-20 19:27:37|2021-10-30 13:07:25| 22.0| Boras|  1|\n",
      "+---+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lectura del CSV\n",
    "df_spark = spark.read.csv(\"./datasets/output/db_retail.csv\",\n",
    "                            header = True,\n",
    "                            sep = \",\",\n",
    "                            nullValue = \"?\",\n",
    "                            encoding = \"utf8\")\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "|         ProductName|ProductQuantity|UnitPrice|Country|  Category|          OrderDate|        ArrivalDate|Sales|  City| ID|\n",
      "+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "|WHITE HANGING HEA...|              6|     2.55|  Italy|Furnishing|2020-03-01 17:00:44|2021-11-17 19:37:57| 15.3|Torino|  0|\n",
      "|CREAM CUPID HEART...|              8|     2.75| Sweden|Furnishing|2018-04-20 14:27:37|2021-10-30 08:07:25| 22.0| Boras|  1|\n",
      "+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lectura del parquet\n",
    "df_spark = spark.read.parquet(\"./datasets/output/db_retail.parquet\",\n",
    "                                header = True,\n",
    "                                sep = \",\",\n",
    "                                nullValue = \"?\",\n",
    "                                encoding = \"utf8\")\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-------+---+-------------+--------------------+---------------+-----+---------+\n",
      "|  ArrivalDate|  Category|  City|Country| ID|    OrderDate|         ProductName|ProductQuantity|Sales|UnitPrice|\n",
      "+-------------+----------+------+-------+---+-------------+--------------------+---------------+-----+---------+\n",
      "|1637195877000|Furnishing|Torino|  Italy|  0|1583100044000|WHITE HANGING HEA...|              6| 15.3|     2.55|\n",
      "|1635599245000|Furnishing| Boras| Sweden|  1|1524252457000|CREAM CUPID HEART...|              8| 22.0|     2.75|\n",
      "+-------------+----------+------+-------+---+-------------+--------------------+---------------+-----+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lectura del JSON\n",
    "df_spark = spark.read.json(\"./datasets/output/db_retail.json\",\n",
    "                            encoding = \"utf8\")\n",
    "df_spark.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definir el esquema de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion que retorna PySpark Schema (lista de schemas de las columnas)\n",
    "def schema(cols_schema: dict) -> StructType:\n",
    "    \"\"\"Define the schema of the dataframe\n",
    "\n",
    "    Args:\n",
    "        cols_schema (dict): Dictionary with the columns and its types\n",
    "\n",
    "    Returns:\n",
    "        StructType: Schema of the dataframe\n",
    "    \"\"\"\n",
    "    return StructType([StructField(key,\n",
    "                                cols_schema[key][0],\n",
    "                                cols_schema[key][1]) for key in cols_schema.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear schema de las columnas con tipos de datos\n",
    "cols_schema = {\n",
    "    \"ID\" : (IntegerType(), False),\n",
    "    \"ProductName\" : (StringType(), False),\n",
    "    \"ProductQuantity\" : (IntegerType(), False),\n",
    "    \"UnitPrice\" : (FloatType(), False),\n",
    "    \"Country\" : (StringType(), False),\n",
    "    \"Category\" : (StringType(), False),\n",
    "    \"OrderDate\" : (DateType(), False),\n",
    "    \"ArrivalDate\" : (DateType(), False),\n",
    "    \"Sales\" : (FloatType(), False),\n",
    "    \"City\" : (StringType(), False)\n",
    "}\n",
    "\n",
    "df_schema = schema(cols_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+-------------+---+\n",
      "|         ProductName|ProductQuantity|UnitPrice|Country|  Category|          OrderDate|        ArrivalDate|Sales|         City| ID|\n",
      "+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+-------------+---+\n",
      "|WHITE HANGING HEA...|              6|     2.55|  Italy|Furnishing|2020-03-01 17:00:44|2021-11-17 19:37:57| 15.3|       Torino|  0|\n",
      "|CREAM CUPID HEART...|              8|     2.75| Sweden|Furnishing|2018-04-20 14:27:37|2021-10-30 08:07:25| 22.0|        Boras|  1|\n",
      "|RED WOOLLY HOTTIE...|              6|     3.39|  Italy|Furnishing|2017-06-20 14:43:13|2017-09-07 23:28:04|20.34|Reggio Emilia|  2|\n",
      "+--------------------+---------------+---------+-------+----------+-------------------+-------------------+-----+-------------+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#forma 1 de uso del esquema\n",
    "df_spark = spark.read.format(\"parquet\")\\\n",
    "                        .option(\"header\", \"true\")\\\n",
    "                        .option(\"nullValue\", \"?\")\\\n",
    "                        .option(\"encoding\", \"utf8\")\\\n",
    "                        .option(\"schema\", df_schema)\\\n",
    "                        .load(\"./datasets/output/db_retail.parquet\")\n",
    "df_spark.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------------+---------+-------+----------+----------+-----------+-----+-------------+\n",
      "| ID|         ProductName|ProductQuantity|UnitPrice|Country|  Category| OrderDate|ArrivalDate|Sales|         City|\n",
      "+---+--------------------+---------------+---------+-------+----------+----------+-----------+-----+-------------+\n",
      "|  0|WHITE HANGING HEA...|              6|     2.55|  Italy|Furnishing|2020-03-01| 2021-11-18| 15.3|       Torino|\n",
      "|  1|CREAM CUPID HEART...|              8|     2.75| Sweden|Furnishing|2018-04-20| 2021-10-30| 22.0|        Boras|\n",
      "|  2|RED WOOLLY HOTTIE...|              6|     3.39|  Italy|Furnishing|2017-06-20| 2017-09-08|20.34|Reggio Emilia|\n",
      "+---+--------------------+---------------+---------+-------+----------+----------+-----------+-----+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#forma 2 de uso del esquema\n",
    "df_spark = spark.read.csv(\"./datasets/output/db_retail.csv\",\n",
    "                           schema = df_schema,\n",
    "                           header = True)\n",
    "df_spark.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calcular medidas de tendencia central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(df) -> dict:\n",
    "    return {\n",
    "            'avg_' + col: df.select(\n",
    "                avg(col).alias('avg_'+col)\n",
    "            ).collect()[0][0]\n",
    "            for col in [column for column, type in df.dtypes if type in ['int', 'float']]\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def get_mode(df) -> dict:\n",
    "    dic_moda = {}\n",
    "    list_dic = []\n",
    "    for item,_ in df.dtypes:\n",
    "        key , value = item+'_Moda', df.filter(col(item).isNotNull()).groupBy(item)\\\n",
    "                                                            .count()\\\n",
    "                                                            .orderBy(\"count\", ascending=False)\\\n",
    "                                                            .collect()[0]\\\n",
    "                                                            .__getitem__(item)\n",
    "        dic_moda[key] = value\n",
    "\n",
    "    list_dic.append(dic_moda)\n",
    "    return list_dic\n",
    "\n",
    "\n",
    "\n",
    "def get_median(df) -> dict:\n",
    "    return {\n",
    "        'median_' + col: df.select(\n",
    "            percentile_approx(col, 0.5).alias('median_'+col)\n",
    "        ).collect()[0][0]\n",
    "        for col in [column for column, type in df.dtypes if type in ['int', 'float']]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_ID': 87799.0,\n",
       " 'avg_ProductQuantity': 13.251649962636973,\n",
       " 'avg_UnitPrice': 15.38569570362877,\n",
       " 'avg_Sales': 36.12007812712544}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mean(df_spark) #calculo de la media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID_Moda': 148,\n",
       "  'ProductName_Moda': 'WHITE HANGING HEART T-LIGHT HOLDER',\n",
       "  'ProductQuantity_Moda': 1,\n",
       "  'UnitPrice_Moda': 1.649999976158142,\n",
       "  'Country_Moda': 'USA',\n",
       "  'Category_Moda': 'Furnishing',\n",
       "  'OrderDate_Moda': datetime.date(2018, 3, 30),\n",
       "  'ArrivalDate_Moda': datetime.date(2021, 12, 30),\n",
       "  'Sales_Moda': 15.0,\n",
       "  'City_Moda': 'Makati City'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mode(df_spark) #calculo de la moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'median_ID': 87793,\n",
       " 'median_ProductQuantity': 5,\n",
       " 'median_UnitPrice': 1.9500000476837158,\n",
       " 'median_Sales': 13.199999809265137}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_median(df_spark) #calculo de la mediana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.createOrReplaceTempView(\"df_sql\") #creando vista SQL de dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------------+-----------------+\n",
      "| AVG_ID|AVG_ProductQuantity|    AVG_UnitPrice|        AVG_Sales|\n",
      "+-------+-------------------+-----------------+-----------------+\n",
      "|87799.0| 13.251649962636973|15.38569570362877|36.12007812712544|\n",
      "+-------+-------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_numerical_cols = \", \".join([f'AVG({column}) as AVG_{column}' for column, type in df_spark.dtypes if type in ['int', 'float']]) #obtengo nombre de columnas numericas con funcion de promedio\n",
    "#obteniendo promedio de columnas numericas\n",
    "spark.sql(f\"\"\"SELECT\n",
    "        {avg_numerical_cols}\n",
    "        FROM df_sql\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------+------------+-------------+--------------+----------------+----------+---------+\n",
      "|ID_Moda|    ProductName_Moda|ProductQuantity_Moda|UnitPrice_Moda|Country_Moda|Category_Moda|OrderDate_Moda|ArrivalDate_Moda|Sales_Moda|City_Moda|\n",
      "+-------+--------------------+--------------------+--------------+------------+-------------+--------------+----------------+----------+---------+\n",
      "| 175598|netTALK DUO VoIP ...|               80995|      22638.48|         USA|          USA|    2021-12-30|      2021-12-30|  168469.6|     Yuma|\n",
      "+-------+--------------------+--------------------+--------------+------------+-------------+--------------+----------------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#obteniendo la moda de las columnas\n",
    "spark.sql(f\"\"\"SELECT\n",
    "        {', '.join([f'MAX({i}) as {i}_Moda' for i,_ in df_spark.dtypes])}\n",
    "        FROM df_sql\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+------------------+------------------+\n",
      "|mediana_ID|mediana_ProductQuantity| mediana_UnitPrice|     mediana_Sales|\n",
      "+----------+-----------------------+------------------+------------------+\n",
      "|   87799.0|                    5.0|1.9500000476837158|13.199999809265137|\n",
      "+----------+-----------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#obteniendo la mediana de las columnas numericas\n",
    "median_numerical_cols = ', '.join([f\"PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY {column}) OVER() AS mediana_{column}\" for column, type in df_spark.dtypes if type in ['int', 'float']])\n",
    "spark.sql(f\"\"\"SELECT\n",
    "        {median_numerical_cols}\n",
    "        FROM df_sql\n",
    "        LIMIT 1\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calcular medidas de dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std(df) -> dict:\n",
    "    return {\n",
    "        'std_' + col: df.select(\n",
    "            stddev(col).alias('std_'+col)\n",
    "        ).collect()[0][0]\n",
    "        for col in [column for column, type in df.dtypes if type in ['int', 'float']]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def get_variance(df) -> dict:\n",
    "    return {\n",
    "        'std_' + col: df.select(\n",
    "            variance(col).alias('std_'+col)\n",
    "        ).collect()[0][0]\n",
    "        for col in [column for column, type in df.dtypes if type in ['int', 'float']]\n",
    "    }\n",
    "    \n",
    " \n",
    "    \n",
    "def get_variance_coef(df) -> dict:\n",
    "    cols_numericas = [column for column, type in df.dtypes if type in ['int', 'float']]\n",
    "    cv = [(stddev(col)/avg(col)).alias('cv_' + col) for col in cols_numericas]\n",
    "    results = df_spark.select(cv).first()\n",
    "    coef_var_dict = dict()\n",
    "\n",
    "    for col in cols_numericas:\n",
    "        cvi= results['cv_'+ col]\n",
    "        coef_var_dict[col] = cvi\n",
    "    return coef_var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'std_ID': 50691.209297076355,\n",
       " 'std_ProductQuantity': 278.00679898616784,\n",
       " 'std_UnitPrice': 156.94964092652415,\n",
       " 'std_Sales': 594.8228326126351}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obteniendo la desviacion estandar\n",
    "get_std(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'std_ID': 2569598700.0,\n",
       " 'std_ProductQuantity': 77287.78028253552,\n",
       " 'std_UnitPrice': 24633.189786964864,\n",
       " 'std_Sales': 353814.2021973189}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obteniendo la varianza\n",
    "get_variance(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 0.5773552010509955,\n",
       " 'ProductQuantity': 20.97903278233337,\n",
       " 'UnitPrice': 10.201010337771534,\n",
       " 'Sales': 16.467927630697325}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obteniendo el coeficiente de variacion\n",
    "get_variance_coef(df_spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Realizar GroupBys con PySpark, SparkSQL y Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|    Country|        sum(Sales)|\n",
      "+-----------+------------------+\n",
      "|     Sweden|195836.90933071822|\n",
      "|Philippines|199859.00949585438|\n",
      "|  Singapore| 194709.9496653825|\n",
      "+-----------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculo de las ventas por pais\n",
    "df_spark.groupBy('Country').sum('Sales').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+\n",
      "|     City|       sum(Sales)|\n",
      "+---------+-----------------+\n",
      "|Minato-ku|100216.9497204572|\n",
      "| Salzburg|98107.91977241635|\n",
      "|   Madrid|70867.61998099089|\n",
      "+---------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculo de las ventas por ciudad\n",
    "df_spark.groupBy('City').sum('Sales').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|ProductQuantity|        sum(Sales)|\n",
      "+---------------+------------------+\n",
      "|             31|126.78999948501587|\n",
      "|             53|  540.069995880127|\n",
      "|            108| 5260.679988861084|\n",
      "+---------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculo de ventas por cantidad de productos ordenados\n",
    "df_spark.groupBy('ProductQuantity').sum('Sales').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|    Country|sum(ProductQuantity)|\n",
      "+-----------+--------------------+\n",
      "|     Sweden|              112326|\n",
      "|Philippines|              116096|\n",
      "|  Singapore|              111412|\n",
      "+-----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculo de unidades ordenadas por pais\n",
    "df_spark.groupBy('Country').sum('ProductQuantity').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|     City|sum(ProductQuantity)|\n",
      "+---------+--------------------+\n",
      "|Minato-ku|               55538|\n",
      "| Salzburg|               53656|\n",
      "|   Madrid|               40485|\n",
      "+---------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculo de unidades ordenadas por ciudad\n",
    "df_spark.groupBy('City').sum('ProductQuantity').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|    Country|    SalesByCountry|\n",
      "+-----------+------------------+\n",
      "|     Sweden|195836.90933071822|\n",
      "|Philippines|199859.00949585438|\n",
      "|  Singapore| 194709.9496653825|\n",
      "+-----------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculo de las ventas por pais\n",
    "spark.sql(\"\"\"\n",
    "    SELECT  Country, sum(Sales) as SalesByCountry\n",
    "    FROM df_sql\n",
    "    GROUP BY Country\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+\n",
      "|     City|      SalesByCity|\n",
      "+---------+-----------------+\n",
      "|Minato-ku|100216.9497204572|\n",
      "| Salzburg|98107.91977241635|\n",
      "|   Madrid|70867.61998099089|\n",
      "+---------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculo de las ventas por ciudad\n",
    "spark.sql(\"\"\"\n",
    "    SELECT  City, sum(Sales) as SalesByCity\n",
    "    FROM df_sql\n",
    "    GROUP BY City\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------------+\n",
      "|ProductQuantity|SalesByProductQuantity|\n",
      "+---------------+----------------------+\n",
      "|             31|    126.78999948501587|\n",
      "|             53|      540.069995880127|\n",
      "|            108|     5260.679988861084|\n",
      "+---------------+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculo de ventas por cantidad de productos ordenados\n",
    "spark.sql(\"\"\"\n",
    "    SELECT  ProductQuantity, sum(Sales) AS SalesByProductQuantity\n",
    "    FROM df_sql\n",
    "    GROUP BY ProductQuantity\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------------------+\n",
      "|    Country|ProductQuantityOrderedByCountry|\n",
      "+-----------+-------------------------------+\n",
      "|     Sweden|                         112326|\n",
      "|Philippines|                         116096|\n",
      "|  Singapore|                         111412|\n",
      "+-----------+-------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculo de unidades ordenadas por pais\n",
    "spark.sql(\"\"\"\n",
    "    SELECT  Country, sum(ProductQuantity) AS ProductQuantityOrderedByCountry\n",
    "    FROM df_sql\n",
    "    GROUP BY Country\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------------------+\n",
      "|     City|ProductQuantityOrderedByCity|\n",
      "+---------+----------------------------+\n",
      "|Minato-ku|                       55538|\n",
      "| Salzburg|                       53656|\n",
      "|   Madrid|                       40485|\n",
      "+---------+----------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#calculo de unidades ordenadas por ciudad\n",
    "spark.sql(\"\"\"\n",
    "    SELECT  City, sum(ProductQuantity) AS ProductQuantityOrderedByCity\n",
    "    FROM df_sql\n",
    "    GROUP BY City\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArrivalDate</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-09 19:10:02</th>\n",
       "      <td>102061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-15 13:03:24</th>\n",
       "      <td>85610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-19 10:32:55</th>\n",
       "      <td>84821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-19 13:31:19</th>\n",
       "      <td>9468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-20 05:33:41</th>\n",
       "      <td>18692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30 23:54:14</th>\n",
       "      <td>134689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30 23:56:05</th>\n",
       "      <td>3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30 23:57:14</th>\n",
       "      <td>14703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30 23:58:30</th>\n",
       "      <td>16250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30 23:59:45</th>\n",
       "      <td>31114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175452 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ID\n",
       "ArrivalDate                \n",
       "2016-01-09 19:10:02  102061\n",
       "2016-01-15 13:03:24   85610\n",
       "2016-01-19 10:32:55   84821\n",
       "2016-01-19 13:31:19    9468\n",
       "2016-01-20 05:33:41   18692\n",
       "...                     ...\n",
       "2021-12-30 23:54:14  134689\n",
       "2021-12-30 23:56:05    3375\n",
       "2021-12-30 23:57:14   14703\n",
       "2021-12-30 23:58:30   16250\n",
       "2021-12-30 23:59:45   31114\n",
       "\n",
       "[175452 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculo de cantidad de unidades que llegan al destino segun la fecha\n",
    "df.groupby([\"ArrivalDate\"]).agg({'ID':'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inner, left y right join con PySpark, SparkSQL y Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars = pd.read_excel(\"./datasets/input/db_cars.xlsx\") \n",
    "df_cars.to_parquet(\"./datasets/output/db_cars.parquet\", engine=\"pyarrow\") #paso excel a parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+------+-------------------+-----------+-----+-------+-------------------+-------------------+---+\n",
      "|ProductQuantity|UnitPrice| Sales|          OrderDate|   Category| City|Country|        ArrivalDate|        ProductName| ID|\n",
      "+---------------+---------+------+-------------------+-----------+-----+-------+-------------------+-------------------+---+\n",
      "|             30|     95.7|2871.0|2017-02-07 17:47:58|Motorcycles|  NYC|    USA|2019-08-20 04:58:17|      Honda Dio Dlx|  0|\n",
      "|             34|    81.35|2765.9|2018-03-02 18:13:56|Motorcycles|Reims| France|2021-06-24 23:55:12|Honda Eco Deluxe Es|  1|\n",
      "+---------------+---------+------+-------------------+-----------+-----+-------+-------------------+-------------------+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cars = spark.read.parquet(\"./datasets/output/db_cars.parquet\", header = True) #lectura de dataset\n",
    "df_cars.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------------+------------------+-----------------------------------+\n",
      "| ID|         ProductName|        ProductName|   (Sales + Sales)|(ProductQuantity + ProductQuantity)|\n",
      "+---+--------------------+-------------------+------------------+-----------------------------------+\n",
      "|  0|WHITE HANGING HEA...|      Honda Dio Dlx| 2886.300000190735|                                 36|\n",
      "|  1|CREAM CUPID HEART...|Honda Eco Deluxe Es|            2787.9|                                 42|\n",
      "|  2|RED WOOLLY HOTTIE...|Honda Eco Deluxe Es| 3904.680000152588|                                 47|\n",
      "|  3|SET 7 BABUSHKA NE...|      Bmw R 1200 Gs|3762.0000001907347|                                 47|\n",
      "|  4|BOX OF VINTAGE JI...|      Bmw R 1200 Gs|  5220.12000038147|                                 52|\n",
      "+---+--------------------+-------------------+------------------+-----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inner jpoin para saber que ordenes tienen tanto productos de retail como carros\n",
    "df_spark.join(df_cars, \"ID\", \"inner\")\\\n",
    "        .select(df_spark.ID, df_spark.ProductName, df_cars.ProductName, (df_spark.Sales + df_cars.Sales), (df_spark.ProductQuantity + df_cars.ProductQuantity))\\\n",
    "        .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left join para obtener todas las ventas de vehiculos y aquellas ordenes de retail asociadas a estas\n",
    "df_cars.join(df_spark, \"ID\", \"left\")\\\n",
    "       .select(df_cars.ID, df_cars.ProductName, df_cars.ProductQuantity ,df_spark.ProductName, df_spark.ProductQuantity, \n",
    "       (df_cars.ProductQuantity + df_spark.ProductQuantity))\\\n",
    "       .show(3) #df_cars es el conjunto de la izquierda, df_spark el de la derecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------------+-------------------+---------------+-----------------------------------+\n",
      "| ID|         ProductName|ProductQuantity|        ProductName|ProductQuantity|(ProductQuantity + ProductQuantity)|\n",
      "+---+--------------------+---------------+-------------------+---------------+-----------------------------------+\n",
      "|  0|WHITE HANGING HEA...|              6|      Honda Dio Dlx|             30|                                 36|\n",
      "|  1|CREAM CUPID HEART...|              8|Honda Eco Deluxe Es|             34|                                 42|\n",
      "|  2|RED WOOLLY HOTTIE...|              6|Honda Eco Deluxe Es|             41|                                 47|\n",
      "+---+--------------------+---------------+-------------------+---------------+-----------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#right join para obtener todas las ordenes de retail y las ventas de vehiculos asociadas a estas\n",
    "df_spark.join(df_cars, \"ID\", \"right\")\\\n",
    "        .select(df_spark.ID, df_spark.ProductName, df_spark.ProductQuantity ,df_cars.ProductName, df_cars.ProductQuantity, \n",
    "        (df_spark.ProductQuantity + df_cars.ProductQuantity))\\\n",
    "        .show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cars.createOrReplaceTempView(\"df_cars_sql\") #creando vista SQL de dataframe de ventas carros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------------+-----------------+----------+\n",
      "| ID|       RetailProduct|        CarsProduct|       TotalSales|TotalUnits|\n",
      "+---+--------------------+-------------------+-----------------+----------+\n",
      "|  0|WHITE HANGING HEA...|      Honda Dio Dlx|2886.300000190735|        36|\n",
      "|  1|CREAM CUPID HEART...|Honda Eco Deluxe Es|           2787.9|        42|\n",
      "|  2|RED WOOLLY HOTTIE...|Honda Eco Deluxe Es|3904.680000152588|        47|\n",
      "+---+--------------------+-------------------+-----------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inner join para saber que ordenes tienen tanto productos de retail como carros\n",
    "spark.sql(\"\"\"\n",
    "          SELECT Retail.ID, Retail.ProductName AS RetailProduct, Cars.ProductName AS CarsProduct, \n",
    "          (Retail.Sales + Cars.Sales) AS TotalSales, (Retail.ProductQuantity + Cars.ProductQuantity) AS TotalUnits\n",
    "          FROM df_sql AS Retail\n",
    "          INNER JOIN df_cars_sql AS Cars\n",
    "          ON Retail.ID = Cars.ID\n",
    "          \"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+-----------+--------------------+-------------+----------+-----------------+\n",
      "| ID|        CarsProduct|CarsQuanity|       RetailProduct|RetailQuanity|TotalUnits|       TotalSales|\n",
      "+---+-------------------+-----------+--------------------+-------------+----------+-----------------+\n",
      "|  0|      Honda Dio Dlx|         30|WHITE HANGING HEA...|            6|        36|2886.300000190735|\n",
      "|  1|Honda Eco Deluxe Es|         34|CREAM CUPID HEART...|            8|        42|           2787.9|\n",
      "|  2|Honda Eco Deluxe Es|         41|RED WOOLLY HOTTIE...|            6|        47|3904.680000152588|\n",
      "+---+-------------------+-----------+--------------------+-------------+----------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#left join para obtener todas las ventas de vehiculos y aquellas ordenes de retail asociadas a estas\n",
    "spark.sql(\"\"\"\n",
    "          SELECT Cars.ID, Cars.ProductName AS CarsProduct, Cars.ProductQuantity AS CarsQuanity, \n",
    "          Retail.ProductName AS RetailProduct, Retail.ProductQuantity AS RetailQuanity, \n",
    "          (Retail.ProductQuantity + Cars.ProductQuantity) AS TotalUnits, (Retail.Sales + Cars.Sales) AS TotalSales\n",
    "          FROM df_cars_sql AS Cars\n",
    "          LEFT JOIN df_sql AS Retail\n",
    "          ON Cars.ID = Retail.ID\n",
    "          \"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------+-------------------+-----------+-----------------+----------+\n",
      "| ID|       RetailProduct|RetailQuanity|        CarsProduct|CarsQuanity|       TotalSales|TotalUnits|\n",
      "+---+--------------------+-------------+-------------------+-----------+-----------------+----------+\n",
      "|  0|WHITE HANGING HEA...|            6|      Honda Dio Dlx|         30|2886.300000190735|        36|\n",
      "|  1|CREAM CUPID HEART...|            8|Honda Eco Deluxe Es|         34|           2787.9|        42|\n",
      "|  2|RED WOOLLY HOTTIE...|            6|Honda Eco Deluxe Es|         41|3904.680000152588|        47|\n",
      "+---+--------------------+-------------+-------------------+-----------+-----------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#right join para obtener todas las ordenes de retail y las ventas de vehiculos asociadas a estas\n",
    "spark.sql(\"\"\"\n",
    "          SELECT Retail.ID, Retail.ProductName AS RetailProduct, Retail.ProductQuantity AS RetailQuanity, \n",
    "          Cars.ProductName AS CarsProduct, Cars.ProductQuantity AS CarsQuanity,\n",
    "          (Retail.Sales + Cars.Sales) AS TotalSales, (Retail.ProductQuantity + Cars.ProductQuantity) AS TotalUnits\n",
    "          FROM df_sql AS Retail\n",
    "          RIGHT JOIN df_cars_sql AS Cars\n",
    "          ON Retail.ID = Cars.ID\n",
    "          \"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leyendo datasets con pandas\n",
    "df_retail = pd.read_excel(\"./datasets/input/db_retail.xlsx\")\n",
    "df_cars = pd.read_excel(\"./datasets/input/db_cars.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName_x</th>\n",
       "      <th>ProductQuantity_x</th>\n",
       "      <th>UnitPrice_x</th>\n",
       "      <th>Country_x</th>\n",
       "      <th>Category_x</th>\n",
       "      <th>OrderDate_x</th>\n",
       "      <th>ArrivalDate_x</th>\n",
       "      <th>Sales_x</th>\n",
       "      <th>City_x</th>\n",
       "      <th>ID</th>\n",
       "      <th>ProductQuantity_y</th>\n",
       "      <th>UnitPrice_y</th>\n",
       "      <th>Sales_y</th>\n",
       "      <th>OrderDate_y</th>\n",
       "      <th>Category_y</th>\n",
       "      <th>City_y</th>\n",
       "      <th>Country_y</th>\n",
       "      <th>ArrivalDate_y</th>\n",
       "      <th>ProductName_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>CHARLOTTE BAG PINK POLKADOT</td>\n",
       "      <td>1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>France</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2019-01-02 23:00:14</td>\n",
       "      <td>2020-08-08 08:02:21</td>\n",
       "      <td>0.85</td>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>2021</td>\n",
       "      <td>41</td>\n",
       "      <td>68.24</td>\n",
       "      <td>2797.84</td>\n",
       "      <td>2021-08-29 03:08:43</td>\n",
       "      <td>Planes</td>\n",
       "      <td>Reims</td>\n",
       "      <td>France</td>\n",
       "      <td>2021-10-04 01:06:44</td>\n",
       "      <td>avianca B747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>JUMBO  BAG BAROQUE BLACK WHITE</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2019-09-26 23:03:12</td>\n",
       "      <td>2021-06-30 08:31:37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>Sevilla</td>\n",
       "      <td>312</td>\n",
       "      <td>34</td>\n",
       "      <td>96.73</td>\n",
       "      <td>3288.82</td>\n",
       "      <td>2017-07-01 12:01:23</td>\n",
       "      <td>Classic Cars</td>\n",
       "      <td>Espoo</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2020-10-26 15:25:06</td>\n",
       "      <td>Volkswagen Jetta Trendline Clasico 2000cc At Aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2541</th>\n",
       "      <td>PLASTERS IN TIN VINTAGE PAISLEY</td>\n",
       "      <td>12</td>\n",
       "      <td>1.65</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Art</td>\n",
       "      <td>2019-01-21 00:47:11</td>\n",
       "      <td>2021-10-28 00:59:38</td>\n",
       "      <td>19.80</td>\n",
       "      <td>Aaarhus</td>\n",
       "      <td>2541</td>\n",
       "      <td>24</td>\n",
       "      <td>99.57</td>\n",
       "      <td>2389.68</td>\n",
       "      <td>2018-02-20 09:26:54</td>\n",
       "      <td>Ships</td>\n",
       "      <td>London</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-05-15 15:37:19</td>\n",
       "      <td>44 cuddy cabin series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         ProductName_x  ProductQuantity_x  UnitPrice_x  \\\n",
       "2021       CHARLOTTE BAG PINK POLKADOT                  1         0.85   \n",
       "312     JUMBO  BAG BAROQUE BLACK WHITE                  1         1.95   \n",
       "2541  PLASTERS IN TIN VINTAGE PAISLEY                  12         1.65   \n",
       "\n",
       "     Country_x   Category_x         OrderDate_x       ArrivalDate_x  Sales_x  \\\n",
       "2021    France  Accessories 2019-01-02 23:00:14 2020-08-08 08:02:21     0.85   \n",
       "312      Spain  Accessories 2019-09-26 23:03:12 2021-06-30 08:31:37     1.95   \n",
       "2541   Denmark          Art 2019-01-21 00:47:11 2021-10-28 00:59:38    19.80   \n",
       "\n",
       "          City_x    ID  ProductQuantity_y  UnitPrice_y  Sales_y  \\\n",
       "2021  Strasbourg  2021                 41        68.24  2797.84   \n",
       "312      Sevilla   312                 34        96.73  3288.82   \n",
       "2541     Aaarhus  2541                 24        99.57  2389.68   \n",
       "\n",
       "             OrderDate_y    Category_y  City_y Country_y       ArrivalDate_y  \\\n",
       "2021 2021-08-29 03:08:43        Planes   Reims    France 2021-10-04 01:06:44   \n",
       "312  2017-07-01 12:01:23  Classic Cars   Espoo   Finland 2020-10-26 15:25:06   \n",
       "2541 2018-02-20 09:26:54         Ships  London        UK 2020-05-15 15:37:19   \n",
       "\n",
       "                                        ProductName_y  \n",
       "2021                                     avianca B747  \n",
       "312   Volkswagen Jetta Trendline Clasico 2000cc At Aa  \n",
       "2541                            44 cuddy cabin series  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inner join para saber que ordenes tienen tanto productos de retail como carros\n",
    "pd.merge(df_retail, df_cars, on = \"ID\", how = \"inner\")\\\n",
    "  .sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductQuantity_x</th>\n",
       "      <th>UnitPrice_x</th>\n",
       "      <th>Sales_x</th>\n",
       "      <th>OrderDate_x</th>\n",
       "      <th>Category_x</th>\n",
       "      <th>City_x</th>\n",
       "      <th>Country_x</th>\n",
       "      <th>ArrivalDate_x</th>\n",
       "      <th>ProductName_x</th>\n",
       "      <th>ID</th>\n",
       "      <th>ProductName_y</th>\n",
       "      <th>ProductQuantity_y</th>\n",
       "      <th>UnitPrice_y</th>\n",
       "      <th>Country_y</th>\n",
       "      <th>Category_y</th>\n",
       "      <th>OrderDate_y</th>\n",
       "      <th>ArrivalDate_y</th>\n",
       "      <th>Sales_y</th>\n",
       "      <th>City_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>46</td>\n",
       "      <td>69.12</td>\n",
       "      <td>3179.52</td>\n",
       "      <td>2018-04-24 11:52:13</td>\n",
       "      <td>Trains</td>\n",
       "      <td>NYC</td>\n",
       "      <td>USA</td>\n",
       "      <td>2019-02-25 02:28:24</td>\n",
       "      <td>Mehano T111</td>\n",
       "      <td>2408</td>\n",
       "      <td>SWEETHEART CERAMIC TRINKET BOX</td>\n",
       "      <td>4</td>\n",
       "      <td>1.25</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Furnishing</td>\n",
       "      <td>2018-05-25 15:54:27</td>\n",
       "      <td>2021-06-01 12:18:15</td>\n",
       "      <td>5.00</td>\n",
       "      <td>Gensve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>30</td>\n",
       "      <td>79.98</td>\n",
       "      <td>2399.40</td>\n",
       "      <td>2020-03-15 15:34:13</td>\n",
       "      <td>Motorcycles</td>\n",
       "      <td>Nantes</td>\n",
       "      <td>France</td>\n",
       "      <td>2021-05-05 21:54:45</td>\n",
       "      <td>Honda Dio Dlx</td>\n",
       "      <td>1578</td>\n",
       "      <td>RED RETROSPOT PEG BAG</td>\n",
       "      <td>6</td>\n",
       "      <td>2.10</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>2021-09-03 01:14:53</td>\n",
       "      <td>2021-12-21 20:04:13</td>\n",
       "      <td>12.60</td>\n",
       "      <td>Kobenhavn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>21</td>\n",
       "      <td>73.60</td>\n",
       "      <td>1545.60</td>\n",
       "      <td>2017-07-14 04:27:24</td>\n",
       "      <td>Classic Cars</td>\n",
       "      <td>North Sydney</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2020-11-07 23:48:24</td>\n",
       "      <td>Ford F-100 Ranger Lariat</td>\n",
       "      <td>1695</td>\n",
       "      <td>HANGING CHICK  YELLOW DECORATION</td>\n",
       "      <td>1</td>\n",
       "      <td>1.45</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Furnishing</td>\n",
       "      <td>2018-07-28 04:02:41</td>\n",
       "      <td>2020-06-14 10:54:45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>Lule</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ProductQuantity_x  UnitPrice_x  Sales_x         OrderDate_x  \\\n",
       "2408                 46        69.12  3179.52 2018-04-24 11:52:13   \n",
       "1578                 30        79.98  2399.40 2020-03-15 15:34:13   \n",
       "1695                 21        73.60  1545.60 2017-07-14 04:27:24   \n",
       "\n",
       "        Category_x        City_x  Country_x       ArrivalDate_x  \\\n",
       "2408        Trains           NYC        USA 2019-02-25 02:28:24   \n",
       "1578   Motorcycles        Nantes     France 2021-05-05 21:54:45   \n",
       "1695  Classic Cars  North Sydney  Australia 2020-11-07 23:48:24   \n",
       "\n",
       "                 ProductName_x    ID                     ProductName_y  \\\n",
       "2408               Mehano T111  2408    SWEETHEART CERAMIC TRINKET BOX   \n",
       "1578             Honda Dio Dlx  1578             RED RETROSPOT PEG BAG   \n",
       "1695  Ford F-100 Ranger Lariat  1695  HANGING CHICK  YELLOW DECORATION   \n",
       "\n",
       "      ProductQuantity_y  UnitPrice_y    Country_y   Category_y  \\\n",
       "2408                  4         1.25  Switzerland   Furnishing   \n",
       "1578                  6         2.10      Denmark  Accessories   \n",
       "1695                  1         1.45       Sweden   Furnishing   \n",
       "\n",
       "             OrderDate_y       ArrivalDate_y  Sales_y     City_y  \n",
       "2408 2018-05-25 15:54:27 2021-06-01 12:18:15     5.00     Gensve  \n",
       "1578 2021-09-03 01:14:53 2021-12-21 20:04:13    12.60  Kobenhavn  \n",
       "1695 2018-07-28 04:02:41 2020-06-14 10:54:45     1.45       Lule  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#left join para obtener todas las ventas de vehiculos y aquellas ordenes de retail asociadas a estas\n",
    "pd.merge(df_cars, df_retail, on = \"ID\", how = \"left\")\\\n",
    ".sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName_x</th>\n",
       "      <th>ProductQuantity_x</th>\n",
       "      <th>UnitPrice_x</th>\n",
       "      <th>Country_x</th>\n",
       "      <th>Category_x</th>\n",
       "      <th>OrderDate_x</th>\n",
       "      <th>ArrivalDate_x</th>\n",
       "      <th>Sales_x</th>\n",
       "      <th>City_x</th>\n",
       "      <th>ID</th>\n",
       "      <th>ProductQuantity_y</th>\n",
       "      <th>UnitPrice_y</th>\n",
       "      <th>Sales_y</th>\n",
       "      <th>OrderDate_y</th>\n",
       "      <th>Category_y</th>\n",
       "      <th>City_y</th>\n",
       "      <th>Country_y</th>\n",
       "      <th>ArrivalDate_y</th>\n",
       "      <th>ProductName_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>CAKE STAND VICTORIAN FILIGREE LARGE</td>\n",
       "      <td>1</td>\n",
       "      <td>8.50</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>2016-11-13 15:47:08</td>\n",
       "      <td>2020-01-31 05:45:01</td>\n",
       "      <td>8.50</td>\n",
       "      <td>North Sydney</td>\n",
       "      <td>2090</td>\n",
       "      <td>44</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4884.88</td>\n",
       "      <td>2021-02-03 18:21:40</td>\n",
       "      <td>Vintage Cars</td>\n",
       "      <td>San Rafael</td>\n",
       "      <td>USA</td>\n",
       "      <td>2021-08-21 08:47:52</td>\n",
       "      <td>Volkwagen Beetle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>BAKING SET SPACEBOY DESIGN</td>\n",
       "      <td>1</td>\n",
       "      <td>4.95</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Furnishing</td>\n",
       "      <td>2019-01-23 16:29:17</td>\n",
       "      <td>2019-06-18 01:02:51</td>\n",
       "      <td>4.95</td>\n",
       "      <td>Lule</td>\n",
       "      <td>1291</td>\n",
       "      <td>43</td>\n",
       "      <td>92.16</td>\n",
       "      <td>3962.88</td>\n",
       "      <td>2018-08-30 18:31:58</td>\n",
       "      <td>Vintage Cars</td>\n",
       "      <td>Madrid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>2019-12-23 07:28:36</td>\n",
       "      <td>1968-1969 Dodge Charger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>CERAMIC STRAWBERRY CAKE MONEY BANK</td>\n",
       "      <td>4</td>\n",
       "      <td>1.45</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Appliances</td>\n",
       "      <td>2016-05-19 14:00:08</td>\n",
       "      <td>2017-11-23 06:40:04</td>\n",
       "      <td>5.80</td>\n",
       "      <td>Makati City</td>\n",
       "      <td>55</td>\n",
       "      <td>29</td>\n",
       "      <td>96.34</td>\n",
       "      <td>2793.86</td>\n",
       "      <td>2021-03-30 07:26:30</td>\n",
       "      <td>Motorcycles</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2021-05-25 13:28:29</td>\n",
       "      <td>Bajaj Pulsar Ns 200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ProductName_x  ProductQuantity_x  UnitPrice_x  \\\n",
       "2090  CAKE STAND VICTORIAN FILIGREE LARGE                  1         8.50   \n",
       "1291           BAKING SET SPACEBOY DESIGN                  1         4.95   \n",
       "55     CERAMIC STRAWBERRY CAKE MONEY BANK                  4         1.45   \n",
       "\n",
       "        Country_x  Category_x         OrderDate_x       ArrivalDate_x  \\\n",
       "2090    Australia  Appliances 2016-11-13 15:47:08 2020-01-31 05:45:01   \n",
       "1291       Sweden  Furnishing 2019-01-23 16:29:17 2019-06-18 01:02:51   \n",
       "55    Philippines  Appliances 2016-05-19 14:00:08 2017-11-23 06:40:04   \n",
       "\n",
       "      Sales_x        City_x    ID  ProductQuantity_y  UnitPrice_y  Sales_y  \\\n",
       "2090     8.50  North Sydney  2090                 44       100.00  4884.88   \n",
       "1291     4.95          Lule  1291                 43        92.16  3962.88   \n",
       "55       5.80   Makati City    55                 29        96.34  2793.86   \n",
       "\n",
       "             OrderDate_y    Category_y      City_y  Country_y  \\\n",
       "2090 2021-02-03 18:21:40  Vintage Cars  San Rafael        USA   \n",
       "1291 2018-08-30 18:31:58  Vintage Cars      Madrid      Spain   \n",
       "55   2021-03-30 07:26:30   Motorcycles   Melbourne  Australia   \n",
       "\n",
       "           ArrivalDate_y            ProductName_y  \n",
       "2090 2021-08-21 08:47:52         Volkwagen Beetle  \n",
       "1291 2019-12-23 07:28:36  1968-1969 Dodge Charger  \n",
       "55   2021-05-25 13:28:29      Bajaj Pulsar Ns 200  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#right join para obtener todas las ordenes de retail y las ventas de vehiculos asociadas a estas\n",
    "pd.merge(df_retail, df_cars, on = \"ID\", how = \"right\")\\\n",
    "  .sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Distinct Count de columnas categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----+\n",
      "|         ProductName|Cantidad|Share|\n",
      "+--------------------+--------+-----+\n",
      "|SET/10 BLUE POLKA...|     235| 0.13|\n",
      "|POTTING SHED SOW ...|       1|  0.0|\n",
      "|SET/3 RED GINGHAM...|     336| 0.19|\n",
      "|MAGNETS PACK OF 4...|      87| 0.05|\n",
      "|PINK  HONEYCOMB P...|      46| 0.03|\n",
      "|PAPERWEIGHT KINGS...|      17| 0.01|\n",
      "|GLASS CAKE COVER ...|       2|  0.0|\n",
      "|JUMBO SHOPPER VIN...|     814| 0.46|\n",
      "|SET OF 4 ENGLISH ...|     142| 0.08|\n",
      "|VINTAGE PAISLEY S...|     216| 0.12|\n",
      "|SET OF 4 NAPKIN C...|     114| 0.06|\n",
      "|RED FLOCK LOVE HE...|      58| 0.03|\n",
      "|SET OF 2 ROUND TI...|      67| 0.04|\n",
      "|SET/10 PINK POLKA...|     318| 0.18|\n",
      "|ZINC METAL HEART ...|     493| 0.28|\n",
      "|WOODEN ROUNDERS G...|     311| 0.18|\n",
      "|CREAM SWEETHEART ...|     481| 0.27|\n",
      "|12 RED ROSE PEG P...|      86| 0.05|\n",
      "|  GREEN ROSE WASHBAG|      49| 0.03|\n",
      "|SET OF 3 CAKE TIN...|    1232|  0.7|\n",
      "+--------------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----------+--------+-----+\n",
      "|    Country|Cantidad|Share|\n",
      "+-----------+--------+-----+\n",
      "|     Sweden|    8689| 4.95|\n",
      "|Philippines|    8773|  5.0|\n",
      "|  Singapore|    8744| 4.98|\n",
      "|    Germany|    8809| 5.02|\n",
      "|     France|    8691| 4.95|\n",
      "|    Belgium|    8751| 4.98|\n",
      "|    Finland|    8937| 5.09|\n",
      "|      Italy|    8805| 5.01|\n",
      "|     Norway|    8739| 4.98|\n",
      "|      Spain|    8575| 4.88|\n",
      "|    Denmark|    8735| 4.97|\n",
      "|    Ireland|    8723| 4.97|\n",
      "|        USA|   18248|10.39|\n",
      "|         UK|    8639| 4.92|\n",
      "|Switzerland|    8694| 4.95|\n",
      "|     Canada|    8641| 4.92|\n",
      "|      Japan|    8669| 4.94|\n",
      "|  Australia|    8682| 4.94|\n",
      "|    Austria|    8763| 4.99|\n",
      "|     27.396|       1|  0.0|\n",
      "+-----------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------------+--------+-----+\n",
      "|       Category|Cantidad|Share|\n",
      "+---------------+--------+-----+\n",
      "|            Art|   14965| 8.52|\n",
      "|     Furnishing|   91567|52.15|\n",
      "|          Paper|    6640| 3.78|\n",
      "|    Accessories|   38053|21.67|\n",
      "|     Appliances|   14574|  8.3|\n",
      "|         98.352|       1|  0.0|\n",
      "|          17.12|       1|  0.0|\n",
      "|         12.294|       2|  0.0|\n",
      "|        295.056|       1|  0.0|\n",
      "|         24.588|       1|  0.0|\n",
      "|Office Supplies|    5670| 3.23|\n",
      "|            USA|     272| 0.15|\n",
      "|      Furniture|    2033| 1.16|\n",
      "|     Technology|    1805| 1.03|\n",
      "|              1|      11| 0.01|\n",
      "|         36.882|       1|  0.0|\n",
      "|          34.24|       1|  0.0|\n",
      "|         65.568|       1|  0.0|\n",
      "+---------------+--------+-----+\n",
      "\n",
      "+------------+--------+-----+\n",
      "|        City|Cantidad|Share|\n",
      "+------------+--------+-----+\n",
      "|   Minato-ku|    4342| 2.47|\n",
      "|    Salzburg|    4388|  2.5|\n",
      "|      Madrid|    2862| 1.63|\n",
      "|   Allentown|     383| 0.22|\n",
      "|       Boras|    4402| 2.51|\n",
      "|        Lule|    4287| 2.44|\n",
      "|White Plains|     374| 0.21|\n",
      "|   Singapore|    8744| 4.98|\n",
      "|  Manchester|    2082| 1.19|\n",
      "|   Frankfurt|    2903| 1.65|\n",
      "|  Brickhaven|     386| 0.22|\n",
      "|Philadelphia|     892| 0.51|\n",
      "|     Stavern|    2950| 1.68|\n",
      "| Los Angeles|    1083| 0.62|\n",
      "|   Cambridge|     375| 0.21|\n",
      "|  Versailles|     968| 0.55|\n",
      "|       Lille|     969| 0.55|\n",
      "|        Oslo|    2958| 1.68|\n",
      "|      Nantes|     994| 0.57|\n",
      "|   Marseille|     968| 0.55|\n",
      "+------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in [column for column, type in df_spark.dtypes if type in ['string']]:\n",
    "    df_spark.groupBy(col)\\\n",
    "    .agg(count(col)\\\n",
    "    .alias('Cantidad'),round((count(col)/df_spark.count())*100,2)\\\n",
    "    .alias('Share')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusiones medidas de tendencia central y dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. En promedio el precio de una unidad es de $15.38 USD, asi mismo el precio maximo promedio esperado por unidad es de unos $172,33 USD (mean + std) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. En promedio las ordenes son de 13 productos, asi mismo el maximo de productos ordenados esperado es de 291 prductos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. El pais que mas aporta ventas en cuanto a volumen, productos adquiridos, es Estados Unidos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. A la hora de realizar un pedido los cliente compran en su mayoria un producto (moda ProductQuantity), esto concuerda con la moda vista en ventas totales y con el promedio del precio por unidad, ya que el total de ventas mas percibido en el conjunto de datos es de $15 USD y asu vez, el precio promedio de la unidad esta en unos $15 USD.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. El producto mas vendido es WHITE HANGING T-LIGHT HOLDER (moda de ProductName) de la categoria Furnishing (moda de Category) y la ciudad en la que mas ordenes se han registrado es Makati City (moda de City)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d591c6e422414675974e227c13f5382000c440fedd3c5006ef2be5d887f0ba7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
